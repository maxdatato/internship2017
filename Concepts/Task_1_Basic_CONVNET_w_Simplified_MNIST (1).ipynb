{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZIFF Summer Internship 2017 Challenge Task 1: Improve accuracy with GridSearch\n",
    "\n",
    "## Objective\n",
    "\n",
    "Demonstrate an understanding of hyperperameter optimization using sklearn GridSearch on a convolutional deep net against a simplified MNIST digit regcognition by improving out-of-sample accuracy above 0.98398.\n",
    "\n",
    "## Submission Criteria\n",
    "\n",
    "  * Follow the instructions in Concepts > Challenge Submission in this project\n",
    "  * Your solution must submitted by Friday June 9th 12:00 midnight\n",
    "\n",
    "## Resources\n",
    "\n",
    "  * [How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras](http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)\n",
    "  * [Deep Learning for Developers](https://www.youtube.com/watch?v=lr3ZZAyHgsM)\n",
    "  * [Lessons learned from 100 deep learning models](https://www.youtube.com/watch?v=HZfNlzziICQ)\n",
    "  * [Machine Learning Mastery](http://machinelearningmastery.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12223, 28, 28, 1)\n",
      "12223 train samples\n",
      "2060 test samples\n",
      "Train on 12223 samples, validate on 2060 samples\n",
      "Epoch 1/50\n",
      "12223/12223 [==============================] - 1s - loss: 0.2531 - acc: 0.8954 - val_loss: 0.0902 - val_acc: 0.9699\n",
      "Epoch 2/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0859 - acc: 0.9708 - val_loss: 0.0747 - val_acc: 0.9767\n",
      "Epoch 3/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0741 - acc: 0.9765 - val_loss: 0.0708 - val_acc: 0.9777\n",
      "Epoch 4/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0676 - acc: 0.9791 - val_loss: 0.0676 - val_acc: 0.9796\n",
      "Epoch 5/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0636 - acc: 0.9812 - val_loss: 0.0563 - val_acc: 0.9806\n",
      "Epoch 6/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0589 - acc: 0.9833 - val_loss: 0.0553 - val_acc: 0.9820\n",
      "Epoch 7/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0562 - acc: 0.9841 - val_loss: 0.0564 - val_acc: 0.9816\n",
      "Epoch 8/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0558 - acc: 0.9845 - val_loss: 0.0569 - val_acc: 0.9811\n",
      "Epoch 9/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0499 - acc: 0.9858 - val_loss: 0.0540 - val_acc: 0.9820\n",
      "Epoch 10/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0499 - acc: 0.9883 - val_loss: 0.0549 - val_acc: 0.9825\n",
      "Epoch 11/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0472 - acc: 0.9872 - val_loss: 0.0479 - val_acc: 0.9825\n",
      "Epoch 12/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0485 - acc: 0.9878 - val_loss: 0.0521 - val_acc: 0.9820\n",
      "Epoch 13/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0493 - acc: 0.9864 - val_loss: 0.0412 - val_acc: 0.9859\n",
      "Epoch 14/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0432 - acc: 0.9884 - val_loss: 0.0421 - val_acc: 0.9859\n",
      "Epoch 15/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0397 - acc: 0.9887 - val_loss: 0.0460 - val_acc: 0.9840\n",
      "Epoch 16/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0381 - acc: 0.9902 - val_loss: 0.0445 - val_acc: 0.9850\n",
      "Epoch 17/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0407 - acc: 0.9899 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "Epoch 18/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0357 - acc: 0.9917 - val_loss: 0.0396 - val_acc: 0.9874\n",
      "Epoch 19/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0369 - acc: 0.9900 - val_loss: 0.0382 - val_acc: 0.9869\n",
      "Epoch 20/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0339 - acc: 0.9908 - val_loss: 0.0413 - val_acc: 0.9874\n",
      "Epoch 21/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0334 - acc: 0.9908 - val_loss: 0.0408 - val_acc: 0.9869\n",
      "Epoch 22/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0373 - acc: 0.9903 - val_loss: 0.0359 - val_acc: 0.9883\n",
      "Epoch 23/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0313 - acc: 0.9920 - val_loss: 0.0386 - val_acc: 0.9879\n",
      "Epoch 24/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0353 - acc: 0.9908 - val_loss: 0.0339 - val_acc: 0.9888\n",
      "Epoch 25/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0341 - acc: 0.9915 - val_loss: 0.0355 - val_acc: 0.9893\n",
      "Epoch 26/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0306 - acc: 0.9923 - val_loss: 0.0363 - val_acc: 0.9888\n",
      "Epoch 27/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0290 - acc: 0.9918 - val_loss: 0.0346 - val_acc: 0.9898\n",
      "Epoch 28/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0311 - acc: 0.9921 - val_loss: 0.0352 - val_acc: 0.9888\n",
      "Epoch 29/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0303 - acc: 0.9924 - val_loss: 0.0358 - val_acc: 0.9898\n",
      "Epoch 30/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0285 - acc: 0.9929 - val_loss: 0.0375 - val_acc: 0.9888\n",
      "Epoch 31/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0289 - acc: 0.9931 - val_loss: 0.0353 - val_acc: 0.9903\n",
      "Epoch 32/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0303 - acc: 0.9921 - val_loss: 0.0327 - val_acc: 0.9903\n",
      "Epoch 33/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0290 - acc: 0.9926 - val_loss: 0.0327 - val_acc: 0.9903\n",
      "Epoch 34/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0296 - acc: 0.9930 - val_loss: 0.0313 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0264 - acc: 0.9936 - val_loss: 0.0337 - val_acc: 0.9908\n",
      "Epoch 36/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0257 - acc: 0.9931 - val_loss: 0.0343 - val_acc: 0.9903\n",
      "Epoch 37/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0256 - acc: 0.9936 - val_loss: 0.0326 - val_acc: 0.9908\n",
      "Epoch 38/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0269 - acc: 0.9936 - val_loss: 0.0324 - val_acc: 0.9908\n",
      "Epoch 39/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0260 - acc: 0.9932 - val_loss: 0.0307 - val_acc: 0.9908\n",
      "Epoch 40/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0274 - acc: 0.9921 - val_loss: 0.0310 - val_acc: 0.9908\n",
      "Epoch 41/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0278 - acc: 0.9938 - val_loss: 0.0293 - val_acc: 0.9913\n",
      "Epoch 42/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0261 - acc: 0.9927 - val_loss: 0.0298 - val_acc: 0.9913\n",
      "Epoch 43/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0242 - acc: 0.9939 - val_loss: 0.0305 - val_acc: 0.9913\n",
      "Epoch 44/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0235 - acc: 0.9945 - val_loss: 0.0316 - val_acc: 0.9908\n",
      "Epoch 45/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0241 - acc: 0.9933 - val_loss: 0.0300 - val_acc: 0.9913\n",
      "Epoch 46/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0243 - acc: 0.9936 - val_loss: 0.0297 - val_acc: 0.9908\n",
      "Epoch 47/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0253 - acc: 0.9935 - val_loss: 0.0277 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0237 - acc: 0.9939 - val_loss: 0.0293 - val_acc: 0.9913\n",
      "Epoch 49/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0221 - acc: 0.9946 - val_loss: 0.0296 - val_acc: 0.9913\n",
      "Epoch 50/50\n",
      "12223/12223 [==============================] - 0s - loss: 0.0260 - acc: 0.9937 - val_loss: 0.0279 - val_acc: 0.9917\n",
      "Test loss: 0.0278599245035\n",
      "Test accuracy: 0.991747572816\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset for ONLY digits 3 and 8.\n",
    "Gets to 98.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "4 seconds per epoch on a 2 GHz Intel Core i5.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Only look at 3s and 8s\n",
    "train_picks = np.logical_or(y_train==2,y_train==7)\n",
    "test_picks = np.logical_or(y_test==2,y_test==7)\n",
    "\n",
    "x_train = x_train[train_picks]\n",
    "x_test = x_test[test_picks]\n",
    "y_train = np.array(y_train[train_picks]==7,dtype=int)\n",
    "y_test = np.array(y_test[test_picks]==7,dtype=int)\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
