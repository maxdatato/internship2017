{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibInternalError",
     "evalue": "JoblibInternalError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_code(code=<code object <module> at 0x7f3b422f21e0, file \"/...3.4/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.4/dist-packages/__pycache__/ipykernel_launcher.cpython-34.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f3b422f21e0, file \"/...3.4/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.4/dist-packages/__pycache__/ipykernel_launcher.cpython-34.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_result = grid.fit(X, Y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 5, 2, 3, 43, 174796, tzinfo=datetime.timezone.utc), 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'session': 'F8AC79D77D53495E8C5F5F6B9BF02DEB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'F8AC79D77D53495E8C5F5F6B9BF02DEB']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_result = grid.fit(X, Y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 5, 2, 3, 43, 174796, tzinfo=datetime.timezone.utc), 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'session': 'F8AC79D77D53495E8C5F5F6B9BF02DEB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'F8AC79D77D53495E8C5F5F6B9BF02DEB'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_result = grid.fit(X, Y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 5, 2, 3, 43, 174796, tzinfo=datetime.timezone.utc), 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'session': 'F8AC79D77D53495E8C5F5F6B9BF02DEB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid_result = grid.fit(X, Y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid_result = grid.fit(X, Y)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid_result = grid.fit(X, Y)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid_result = grid.fit(X, Y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_result = grid.fit(X, Y)', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-3-fb6ebddf1611>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f3a9f8526d8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3aa296e9c0, file \"<ipython-input-3-fb6ebddf1611>\", line 1>\n        result = <ExecutionResult object at 7f3a9f8526d8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3aa296e9c0, file \"<ipython-input-3-fb6ebddf1611>\", line 1>, result=<ExecutionResult object at 7f3a9f8526d8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3aa296e9c0, file \"<ipython-input-3-fb6ebddf1611>\", line 1>\n        self.user_global_ns = {'Dense': <class 'keras.layers.core.Dense'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Use scikit-learn to grid search the batch size...(Y) variables\\nX = dataset[:,0:8]\\nY = dataset[:,8]', '# create model\\nmodel = KerasClassifier(build_fn=...stimator=model, param_grid=param_grid, n_jobs=-1)', 'grid_result = grid.fit(X, Y)'], 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'Out': {}, 'Sequential': <class 'keras.models.Sequential'>, 'X': array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), 'Y': array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), '_': '', '__': '', ...}\n        self.user_ns = {'Dense': <class 'keras.layers.core.Dense'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Use scikit-learn to grid search the batch size...(Y) variables\\nX = dataset[:,0:8]\\nY = dataset[:,8]', '# create model\\nmodel = KerasClassifier(build_fn=...stimator=model, param_grid=param_grid, n_jobs=-1)', 'grid_result = grid.fit(X, Y)'], 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'Out': {}, 'Sequential': <class 'keras.models.Sequential'>, 'X': array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), 'Y': array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), '_': '', '__': '', ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/opt/pynb/internship2017/Challenges/<ipython-input-3-fb6ebddf1611> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 grid_result = grid.fit(X, Y)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]])\n        y = array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.])\n        groups = None\n        self.param_grid = {'batch_size': [10, 20, 40, 60, 80, 100], 'epochs': [10, 50, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nInternalError                                      Mon Jun  5 02:03:44 2017\nPID: 25107                                   Python 3.4.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), scorer=<function _passthrough_scorer>, train=array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), verbose=0, parameters={'batch_size': 10, 'epochs': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y_train = array([ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  1.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    196             self.classes_ = np.arange(y.shape[1])\n    197         else:\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         self.n_classes_ = len(self.classes_)\n--> 201         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        kwargs = {}\n    202 \n    203     def predict(self, x, **kwargs):\n    204         \"\"\"Returns the class predictions for the given test data.\n    205 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    144             y = to_categorical(y)\n    145 \n    146         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    147         fit_args.update(kwargs)\n    148 \n--> 149         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        fit_args = {'batch_size': 10, 'epochs': 10, 'verbose': 0}\n    150 \n    151         return history\n    152 \n    153     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n    840                               validation_split=validation_split,\n    841                               validation_data=validation_data,\n    842                               shuffle=shuffle,\n    843                               class_weight=class_weight,\n    844                               sample_weight=sample_weight,\n--> 845                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n    846 \n    847     def evaluate(self, x, y, batch_size=32, verbose=1,\n    848                  sample_weight=None):\n    849         \"\"\"Computes the loss on some input data, batch by batch.\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])], y=[array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]])], batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n   1480         return self._fit_loop(f, ins, out_labels=out_labels,\n   1481                               batch_size=batch_size, epochs=epochs,\n   1482                               verbose=verbose, callbacks=callbacks,\n   1483                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1484                               callback_metrics=callback_metrics,\n-> 1485                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n   1486 \n   1487     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):\n   1488         \"\"\"Returns the loss value & metrics values for the model in test mode.\n   1489 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  ...,\n        1.,  1.,  1.,  1.,  1.], dtype=float32)], out_labels=['loss', 'acc'], batch_size=10, epochs=10, verbose=0, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=None, shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0)\n   1135                                     'pass shuffle=\"batch\".')\n   1136                 batch_logs = {}\n   1137                 batch_logs['batch'] = batch_index\n   1138                 batch_logs['size'] = len(batch_ids)\n   1139                 callbacks.on_batch_begin(batch_index, batch_logs)\n-> 1140                 outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)]\n   1141                 if not isinstance(outs, list):\n   1142                     outs = [outs]\n   1143                 for l, o in zip(out_labels, outs):\n   1144                     batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)])\n   2066                 sparse_coo = value.tocoo()\n   2067                 indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n   2068                                           np.expand_dims(sparse_coo.col, 1)), 1)\n   2069                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2070             feed_dict[tensor] = value\n-> 2071         session = get_session()\n        session = undefined\n   2072         updated = session.run(self.outputs + [self.updates_op],\n   2073                               feed_dict=feed_dict)\n   2074         return updated[:len(self.outputs)]\n   2075 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in get_session()\n    145                 config = tf.ConfigProto(allow_soft_placement=True)\n    146             else:\n    147                 num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n    148                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n    149                                         allow_soft_placement=True)\n--> 150             _SESSION = tf.Session(config=config)\n        config = allow_soft_placement: true\n\n    151         session = _SESSION\n    152     if not _MANUAL_VAR_INIT:\n    153         _initialize_variables()\n    154     return session\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n   1188       graph: (Optional.) The `Graph` to be launched (described above).\n   1189       config: (Optional.) A [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n   1190         protocol buffer with configuration options for the session.\n   1191 \n   1192     \"\"\"\n-> 1193     super(Session, self).__init__(target, graph, config=config)\n        self.__init__ = <bound method Session.__init__ of <tensorflow.python.client.session.Session object>>\n        target = ''\n        graph = None\n        config = allow_soft_placement: true\n\n   1194     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\n   1195     self._default_graph_context_manager = None\n   1196     self._default_session_context_manager = None\n   1197 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n    549 \n    550     self._session = None\n    551     opts = tf_session.TF_NewSessionOptions(target=self._target, config=config)\n    552     try:\n    553       with errors.raise_exception_on_not_ok_status() as status:\n--> 554         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n        self._session = None\n        opts = <Swig Object of type 'TF_SessionOptions *'>\n        status = <Swig Object of type 'TF_Status *'>\n    555     finally:\n    556       tf_session.TF_DeleteSessionOptions(opts)\n    557 \n    558   def close(self):\n\n...........................................................................\n/usr/lib/python3.4/contextlib.py in __exit__(self=<contextlib._GeneratorContextManager object>, type=None, value=None, traceback=None)\n     61             raise RuntimeError(\"generator didn't yield\") from None\n     62 \n     63     def __exit__(self, type, value, traceback):\n     64         if type is None:\n     65             try:\n---> 66                 next(self.gen)\n        self.gen = <generator object raise_exception_on_not_ok_status>\n     67             except StopIteration:\n     68                 return\n     69             else:\n     70                 raise RuntimeError(\"generator didn't stop\")\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    461     yield status\n    462     if pywrap_tensorflow.TF_GetCode(status) != 0:\n    463       raise _make_specific_exception(\n    464           None, None,\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n        status = <Swig Object of type 'TF_Status *'>\n    467   finally:\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\n    469 \n    470 \n\nInternalError: Failed to create session.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py\", line 201, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py\", line 149, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/usr/local/lib/python3.4/dist-packages/keras/models.py\", line 845, in fit\n    initial_epoch=initial_epoch)\n  File \"/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\", line 1485, in fit\n    initial_epoch=initial_epoch)\n  File \"/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\", line 1140, in _fit_loop\n    outs = f(ins_batch)\n  File \"/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py\", line 2071, in __call__\n    session = get_session()\n  File \"/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py\", line 150, in get_session\n    _SESSION = tf.Session(config=config)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 1193, in __init__\n    super(Session, self).__init__(target, graph, config=config)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 554, in __init__\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nInternalError                                      Mon Jun  5 02:03:44 2017\nPID: 25107                                   Python 3.4.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), scorer=<function _passthrough_scorer>, train=array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), verbose=0, parameters={'batch_size': 10, 'epochs': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y_train = array([ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  1.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    196             self.classes_ = np.arange(y.shape[1])\n    197         else:\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         self.n_classes_ = len(self.classes_)\n--> 201         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        kwargs = {}\n    202 \n    203     def predict(self, x, **kwargs):\n    204         \"\"\"Returns the class predictions for the given test data.\n    205 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    144             y = to_categorical(y)\n    145 \n    146         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    147         fit_args.update(kwargs)\n    148 \n--> 149         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        fit_args = {'batch_size': 10, 'epochs': 10, 'verbose': 0}\n    150 \n    151         return history\n    152 \n    153     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n    840                               validation_split=validation_split,\n    841                               validation_data=validation_data,\n    842                               shuffle=shuffle,\n    843                               class_weight=class_weight,\n    844                               sample_weight=sample_weight,\n--> 845                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n    846 \n    847     def evaluate(self, x, y, batch_size=32, verbose=1,\n    848                  sample_weight=None):\n    849         \"\"\"Computes the loss on some input data, batch by batch.\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])], y=[array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]])], batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n   1480         return self._fit_loop(f, ins, out_labels=out_labels,\n   1481                               batch_size=batch_size, epochs=epochs,\n   1482                               verbose=verbose, callbacks=callbacks,\n   1483                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1484                               callback_metrics=callback_metrics,\n-> 1485                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n   1486 \n   1487     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):\n   1488         \"\"\"Returns the loss value & metrics values for the model in test mode.\n   1489 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  ...,\n        1.,  1.,  1.,  1.,  1.], dtype=float32)], out_labels=['loss', 'acc'], batch_size=10, epochs=10, verbose=0, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=None, shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0)\n   1135                                     'pass shuffle=\"batch\".')\n   1136                 batch_logs = {}\n   1137                 batch_logs['batch'] = batch_index\n   1138                 batch_logs['size'] = len(batch_ids)\n   1139                 callbacks.on_batch_begin(batch_index, batch_logs)\n-> 1140                 outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)]\n   1141                 if not isinstance(outs, list):\n   1142                     outs = [outs]\n   1143                 for l, o in zip(out_labels, outs):\n   1144                     batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)])\n   2066                 sparse_coo = value.tocoo()\n   2067                 indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n   2068                                           np.expand_dims(sparse_coo.col, 1)), 1)\n   2069                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2070             feed_dict[tensor] = value\n-> 2071         session = get_session()\n        session = undefined\n   2072         updated = session.run(self.outputs + [self.updates_op],\n   2073                               feed_dict=feed_dict)\n   2074         return updated[:len(self.outputs)]\n   2075 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in get_session()\n    145                 config = tf.ConfigProto(allow_soft_placement=True)\n    146             else:\n    147                 num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n    148                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n    149                                         allow_soft_placement=True)\n--> 150             _SESSION = tf.Session(config=config)\n        config = allow_soft_placement: true\n\n    151         session = _SESSION\n    152     if not _MANUAL_VAR_INIT:\n    153         _initialize_variables()\n    154     return session\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n   1188       graph: (Optional.) The `Graph` to be launched (described above).\n   1189       config: (Optional.) A [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n   1190         protocol buffer with configuration options for the session.\n   1191 \n   1192     \"\"\"\n-> 1193     super(Session, self).__init__(target, graph, config=config)\n        self.__init__ = <bound method Session.__init__ of <tensorflow.python.client.session.Session object>>\n        target = ''\n        graph = None\n        config = allow_soft_placement: true\n\n   1194     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\n   1195     self._default_graph_context_manager = None\n   1196     self._default_session_context_manager = None\n   1197 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n    549 \n    550     self._session = None\n    551     opts = tf_session.TF_NewSessionOptions(target=self._target, config=config)\n    552     try:\n    553       with errors.raise_exception_on_not_ok_status() as status:\n--> 554         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n        self._session = None\n        opts = <Swig Object of type 'TF_SessionOptions *'>\n        status = <Swig Object of type 'TF_Status *'>\n    555     finally:\n    556       tf_session.TF_DeleteSessionOptions(opts)\n    557 \n    558   def close(self):\n\n...........................................................................\n/usr/lib/python3.4/contextlib.py in __exit__(self=<contextlib._GeneratorContextManager object>, type=None, value=None, traceback=None)\n     61             raise RuntimeError(\"generator didn't yield\") from None\n     62 \n     63     def __exit__(self, type, value, traceback):\n     64         if type is None:\n     65             try:\n---> 66                 next(self.gen)\n        self.gen = <generator object raise_exception_on_not_ok_status>\n     67             except StopIteration:\n     68                 return\n     69             else:\n     70                 raise RuntimeError(\"generator didn't stop\")\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    461     yield status\n    462     if pywrap_tensorflow.TF_GetCode(status) != 0:\n    463       raise _make_specific_exception(\n    464           None, None,\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n        status = <Swig Object of type 'TF_Status *'>\n    467   finally:\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\n    469 \n    470 \n\nInternalError: Failed to create session.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nInternalError                                      Mon Jun  5 02:03:44 2017\nPID: 25107                                   Python 3.4.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), scorer=<function _passthrough_scorer>, train=array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), verbose=0, parameters={'batch_size': 10, 'epochs': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y_train = array([ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  1.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    196             self.classes_ = np.arange(y.shape[1])\n    197         else:\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         self.n_classes_ = len(self.classes_)\n--> 201         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        kwargs = {}\n    202 \n    203     def predict(self, x, **kwargs):\n    204         \"\"\"Returns the class predictions for the given test data.\n    205 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    144             y = to_categorical(y)\n    145 \n    146         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    147         fit_args.update(kwargs)\n    148 \n--> 149         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        fit_args = {'batch_size': 10, 'epochs': 10, 'verbose': 0}\n    150 \n    151         return history\n    152 \n    153     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n    840                               validation_split=validation_split,\n    841                               validation_data=validation_data,\n    842                               shuffle=shuffle,\n    843                               class_weight=class_weight,\n    844                               sample_weight=sample_weight,\n--> 845                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n    846 \n    847     def evaluate(self, x, y, batch_size=32, verbose=1,\n    848                  sample_weight=None):\n    849         \"\"\"Computes the loss on some input data, batch by batch.\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])], y=[array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]])], batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n   1480         return self._fit_loop(f, ins, out_labels=out_labels,\n   1481                               batch_size=batch_size, epochs=epochs,\n   1482                               verbose=verbose, callbacks=callbacks,\n   1483                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1484                               callback_metrics=callback_metrics,\n-> 1485                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n   1486 \n   1487     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):\n   1488         \"\"\"Returns the loss value & metrics values for the model in test mode.\n   1489 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  ...,\n        1.,  1.,  1.,  1.,  1.], dtype=float32)], out_labels=['loss', 'acc'], batch_size=10, epochs=10, verbose=0, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=None, shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0)\n   1135                                     'pass shuffle=\"batch\".')\n   1136                 batch_logs = {}\n   1137                 batch_logs['batch'] = batch_index\n   1138                 batch_logs['size'] = len(batch_ids)\n   1139                 callbacks.on_batch_begin(batch_index, batch_logs)\n-> 1140                 outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)]\n   1141                 if not isinstance(outs, list):\n   1142                     outs = [outs]\n   1143                 for l, o in zip(out_labels, outs):\n   1144                     batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)])\n   2066                 sparse_coo = value.tocoo()\n   2067                 indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n   2068                                           np.expand_dims(sparse_coo.col, 1)), 1)\n   2069                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2070             feed_dict[tensor] = value\n-> 2071         session = get_session()\n        session = undefined\n   2072         updated = session.run(self.outputs + [self.updates_op],\n   2073                               feed_dict=feed_dict)\n   2074         return updated[:len(self.outputs)]\n   2075 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in get_session()\n    145                 config = tf.ConfigProto(allow_soft_placement=True)\n    146             else:\n    147                 num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n    148                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n    149                                         allow_soft_placement=True)\n--> 150             _SESSION = tf.Session(config=config)\n        config = allow_soft_placement: true\n\n    151         session = _SESSION\n    152     if not _MANUAL_VAR_INIT:\n    153         _initialize_variables()\n    154     return session\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n   1188       graph: (Optional.) The `Graph` to be launched (described above).\n   1189       config: (Optional.) A [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n   1190         protocol buffer with configuration options for the session.\n   1191 \n   1192     \"\"\"\n-> 1193     super(Session, self).__init__(target, graph, config=config)\n        self.__init__ = <bound method Session.__init__ of <tensorflow.python.client.session.Session object>>\n        target = ''\n        graph = None\n        config = allow_soft_placement: true\n\n   1194     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\n   1195     self._default_graph_context_manager = None\n   1196     self._default_session_context_manager = None\n   1197 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n    549 \n    550     self._session = None\n    551     opts = tf_session.TF_NewSessionOptions(target=self._target, config=config)\n    552     try:\n    553       with errors.raise_exception_on_not_ok_status() as status:\n--> 554         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n        self._session = None\n        opts = <Swig Object of type 'TF_SessionOptions *'>\n        status = <Swig Object of type 'TF_Status *'>\n    555     finally:\n    556       tf_session.TF_DeleteSessionOptions(opts)\n    557 \n    558   def close(self):\n\n...........................................................................\n/usr/lib/python3.4/contextlib.py in __exit__(self=<contextlib._GeneratorContextManager object>, type=None, value=None, traceback=None)\n     61             raise RuntimeError(\"generator didn't yield\") from None\n     62 \n     63     def __exit__(self, type, value, traceback):\n     64         if type is None:\n     65             try:\n---> 66                 next(self.gen)\n        self.gen = <generator object raise_exception_on_not_ok_status>\n     67             except StopIteration:\n     68                 return\n     69             else:\n     70                 raise RuntimeError(\"generator didn't stop\")\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    461     yield status\n    462     if pywrap_tensorflow.TF_GetCode(status) != 0:\n    463       raise _make_specific_exception(\n    464           None, None,\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n        status = <Swig Object of type 'TF_Status *'>\n    467   finally:\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\n    469 \n    470 \n\nInternalError: Failed to create session.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibInternalError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fb6ebddf1611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibInternalError\u001b[0m: JoblibInternalError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_code(code=<code object <module> at 0x7f3b422f21e0, file \"/...3.4/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.4/dist-packages/__pycache__/ipykernel_launcher.cpython-34.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f3b422f21e0, file \"/...3.4/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.4/dist-packages/__pycache__/ipykernel_launcher.cpython-34.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.4/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_result = grid.fit(X, Y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 5, 2, 3, 43, 174796, tzinfo=datetime.timezone.utc), 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'session': 'F8AC79D77D53495E8C5F5F6B9BF02DEB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'F8AC79D77D53495E8C5F5F6B9BF02DEB']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_result = grid.fit(X, Y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 5, 2, 3, 43, 174796, tzinfo=datetime.timezone.utc), 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'session': 'F8AC79D77D53495E8C5F5F6B9BF02DEB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'F8AC79D77D53495E8C5F5F6B9BF02DEB'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_result = grid.fit(X, Y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 5, 2, 3, 43, 174796, tzinfo=datetime.timezone.utc), 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'session': 'F8AC79D77D53495E8C5F5F6B9BF02DEB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '080BFBF5169840F38A8FA3381DCF392F', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid_result = grid.fit(X, Y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid_result = grid.fit(X, Y)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid_result = grid.fit(X, Y)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid_result = grid.fit(X, Y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_result = grid.fit(X, Y)', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-3-fb6ebddf1611>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f3a9f8526d8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3aa296e9c0, file \"<ipython-input-3-fb6ebddf1611>\", line 1>\n        result = <ExecutionResult object at 7f3a9f8526d8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3aa296e9c0, file \"<ipython-input-3-fb6ebddf1611>\", line 1>, result=<ExecutionResult object at 7f3a9f8526d8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3aa296e9c0, file \"<ipython-input-3-fb6ebddf1611>\", line 1>\n        self.user_global_ns = {'Dense': <class 'keras.layers.core.Dense'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Use scikit-learn to grid search the batch size...(Y) variables\\nX = dataset[:,0:8]\\nY = dataset[:,8]', '# create model\\nmodel = KerasClassifier(build_fn=...stimator=model, param_grid=param_grid, n_jobs=-1)', 'grid_result = grid.fit(X, Y)'], 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'Out': {}, 'Sequential': <class 'keras.models.Sequential'>, 'X': array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), 'Y': array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), '_': '', '__': '', ...}\n        self.user_ns = {'Dense': <class 'keras.layers.core.Dense'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Use scikit-learn to grid search the batch size...(Y) variables\\nX = dataset[:,0:8]\\nY = dataset[:,8]', '# create model\\nmodel = KerasClassifier(build_fn=...stimator=model, param_grid=param_grid, n_jobs=-1)', 'grid_result = grid.fit(X, Y)'], 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'Out': {}, 'Sequential': <class 'keras.models.Sequential'>, 'X': array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), 'Y': array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), '_': '', '__': '', ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/opt/pynb/internship2017/Challenges/<ipython-input-3-fb6ebddf1611> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 grid_result = grid.fit(X, Y)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]])\n        y = array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.])\n        groups = None\n        self.param_grid = {'batch_size': [10, 20, 40, 60, 80, 100], 'epochs': [10, 50, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nInternalError                                      Mon Jun  5 02:03:44 2017\nPID: 25107                                   Python 3.4.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), <function _passthrough_scorer>, array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), 0, {'batch_size': 10, 'epochs': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=array([[   6.   ,  148.   ,   72.   , ...,   33.... ,   70.   , ...,   30.4  ,    0.315,   23.   ]]), y=array([ 1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  ...0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]), scorer=<function _passthrough_scorer>, train=array([256, 257, 258, 259, 260, 261, 262, 263, 2..., 760, 761, 762,\n       763, 764, 765, 766, 767]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    247, 248, 249, 250, 251, 252, 253, 254, 255]), verbose=0, parameters={'batch_size': 10, 'epochs': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y_train = array([ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  1.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    196             self.classes_ = np.arange(y.shape[1])\n    197         else:\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         self.n_classes_ = len(self.classes_)\n--> 201         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        kwargs = {}\n    202 \n    203     def predict(self, x, **kwargs):\n    204         \"\"\"Returns the class predictions for the given test data.\n    205 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), **kwargs={})\n    144             y = to_categorical(y)\n    145 \n    146         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    147         fit_args.update(kwargs)\n    148 \n--> 149         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])\n        y = array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0])\n        fit_args = {'batch_size': 10, 'epochs': 10, 'verbose': 0}\n    150 \n    151         return history\n    152 \n    153     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), y=array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,...1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0]), batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n    840                               validation_split=validation_split,\n    841                               validation_data=validation_data,\n    842                               shuffle=shuffle,\n    843                               class_weight=class_weight,\n    844                               sample_weight=sample_weight,\n--> 845                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n    846 \n    847     def evaluate(self, x, y, batch_size=32, verbose=1,\n    848                  sample_weight=None):\n    849         \"\"\"Computes the loss on some input data, batch by batch.\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]])], y=[array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]])], batch_size=10, epochs=10, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs={})\n   1480         return self._fit_loop(f, ins, out_labels=out_labels,\n   1481                               batch_size=batch_size, epochs=epochs,\n   1482                               verbose=verbose, callbacks=callbacks,\n   1483                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1484                               callback_metrics=callback_metrics,\n-> 1485                               initial_epoch=initial_epoch)\n        initial_epoch = 0\n   1486 \n   1487     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):\n   1488         \"\"\"Returns the loss value & metrics values for the model in test mode.\n   1489 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[array([[  3.00000000e+00,   1.11000000e+02,   5....000000e+01,   3.15000000e-01,   2.30000000e+01]]), array([[0],\n       [0],\n       [0],\n       [1],\n...\n       [0],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  ...,\n        1.,  1.,  1.,  1.,  1.], dtype=float32)], out_labels=['loss', 'acc'], batch_size=10, epochs=10, verbose=0, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=None, shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0)\n   1135                                     'pass shuffle=\"batch\".')\n   1136                 batch_logs = {}\n   1137                 batch_logs['batch'] = batch_index\n   1138                 batch_logs['size'] = len(batch_ids)\n   1139                 callbacks.on_batch_begin(batch_index, batch_logs)\n-> 1140                 outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)]\n   1141                 if not isinstance(outs, list):\n   1142                     outs = [outs]\n   1143                 for l, o in zip(out_labels, outs):\n   1144                     batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[  1.10000000e+01,   1.03000000e+02,   6....01,\n          1.51000000e-01,   5.50000000e+01]]), array([[0],\n       [0],\n       [0],\n       [0],\n...\n       [1],\n       [0],\n       [1],\n       [0]]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)])\n   2066                 sparse_coo = value.tocoo()\n   2067                 indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n   2068                                           np.expand_dims(sparse_coo.col, 1)), 1)\n   2069                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2070             feed_dict[tensor] = value\n-> 2071         session = get_session()\n        session = undefined\n   2072         updated = session.run(self.outputs + [self.updates_op],\n   2073                               feed_dict=feed_dict)\n   2074         return updated[:len(self.outputs)]\n   2075 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py in get_session()\n    145                 config = tf.ConfigProto(allow_soft_placement=True)\n    146             else:\n    147                 num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n    148                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n    149                                         allow_soft_placement=True)\n--> 150             _SESSION = tf.Session(config=config)\n        config = allow_soft_placement: true\n\n    151         session = _SESSION\n    152     if not _MANUAL_VAR_INIT:\n    153         _initialize_variables()\n    154     return session\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n   1188       graph: (Optional.) The `Graph` to be launched (described above).\n   1189       config: (Optional.) A [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n   1190         protocol buffer with configuration options for the session.\n   1191 \n   1192     \"\"\"\n-> 1193     super(Session, self).__init__(target, graph, config=config)\n        self.__init__ = <bound method Session.__init__ of <tensorflow.python.client.session.Session object>>\n        target = ''\n        graph = None\n        config = allow_soft_placement: true\n\n   1194     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\n   1195     self._default_graph_context_manager = None\n   1196     self._default_session_context_manager = None\n   1197 \n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py in __init__(self=<tensorflow.python.client.session.Session object>, target='', graph=None, config=allow_soft_placement: true\n)\n    549 \n    550     self._session = None\n    551     opts = tf_session.TF_NewSessionOptions(target=self._target, config=config)\n    552     try:\n    553       with errors.raise_exception_on_not_ok_status() as status:\n--> 554         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n        self._session = None\n        opts = <Swig Object of type 'TF_SessionOptions *'>\n        status = <Swig Object of type 'TF_Status *'>\n    555     finally:\n    556       tf_session.TF_DeleteSessionOptions(opts)\n    557 \n    558   def close(self):\n\n...........................................................................\n/usr/lib/python3.4/contextlib.py in __exit__(self=<contextlib._GeneratorContextManager object>, type=None, value=None, traceback=None)\n     61             raise RuntimeError(\"generator didn't yield\") from None\n     62 \n     63     def __exit__(self, type, value, traceback):\n     64         if type is None:\n     65             try:\n---> 66                 next(self.gen)\n        self.gen = <generator object raise_exception_on_not_ok_status>\n     67             except StopIteration:\n     68                 return\n     69             else:\n     70                 raise RuntimeError(\"generator didn't stop\")\n\n...........................................................................\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    461     yield status\n    462     if pywrap_tensorflow.TF_GetCode(status) != 0:\n    463       raise _make_specific_exception(\n    464           None, None,\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n        status = <Swig Object of type 'TF_Status *'>\n    467   finally:\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\n    469 \n    470 \n\nInternalError: Failed to create session.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
