{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZIFF Summer Internship 2017 Challenge Task 1: Improve accuracy with GridSearch\n",
    "\n",
    "## Objective\n",
    "\n",
    "Demonstrate an understanding of hyperperameter optimization using sklearn GridSearch on a convolutional deep net against a simplified MNIST digit regcognition by improving out-of-sample accuracy above 0.98398.\n",
    "\n",
    "## Submission Criteria\n",
    "\n",
    "  * Follow the instructions in Concepts > Challenge Submission in this project\n",
    "  * Your solution must submitted by Friday June 9th 12:00 midnight\n",
    "\n",
    "## Resources\n",
    "\n",
    "  * [How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras](http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)\n",
    "  * [Deep Learning for Developers](https://www.youtube.com/watch?v=lr3ZZAyHgsM)\n",
    "  * [Lessons learned from 100 deep learning models](https://www.youtube.com/watch?v=HZfNlzziICQ)\n",
    "  * [Machine Learning Mastery](http://machinelearningmastery.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "x_train shape: (12223, 28, 28, 1)\n",
      "12223 train samples\n",
      "2060 test samples\n",
      "Train on 12223 samples, validate on 2060 samples\n",
      "Epoch 1/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.2756 - acc: 0.8985 - val_loss: 0.0760 - val_acc: 0.9748\n",
      "Epoch 2/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.0835 - acc: 0.9741 - val_loss: 0.0698 - val_acc: 0.9767\n",
      "Epoch 3/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.0670 - acc: 0.9797 - val_loss: 0.0715 - val_acc: 0.9772\n",
      "Epoch 4/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0560 - acc: 0.9818 - val_loss: 0.0628 - val_acc: 0.9816\n",
      "Epoch 5/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.0586 - acc: 0.9831 - val_loss: 0.0566 - val_acc: 0.9835\n",
      "Epoch 6/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0519 - acc: 0.9840 - val_loss: 0.0589 - val_acc: 0.9811\n",
      "Epoch 7/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0503 - acc: 0.9858 - val_loss: 0.0536 - val_acc: 0.9845\n",
      "Epoch 8/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0503 - acc: 0.9850 - val_loss: 0.0553 - val_acc: 0.9835\n",
      "Epoch 9/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0457 - acc: 0.9867 - val_loss: 0.0525 - val_acc: 0.9840\n",
      "Epoch 10/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.0474 - acc: 0.9850 - val_loss: 0.0509 - val_acc: 0.9840\n",
      "Epoch 11/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.0461 - acc: 0.9867 - val_loss: 0.0493 - val_acc: 0.9845\n",
      "Epoch 12/12\n",
      "12223/12223 [==============================] - 5s - loss: 0.0449 - acc: 0.9882 - val_loss: 0.0490 - val_acc: 0.9850\n",
      "Test loss: 0.049024477387\n",
      "Test accuracy: 0.984951456311\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset for ONLY digits 3 and 8.\n",
    "Gets to 98.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "4 seconds per epoch on a 2 GHz Intel Core i5.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Only look at 3s and 8s\n",
    "train_picks = np.logical_or(y_train==2,y_train==7)\n",
    "test_picks = np.logical_or(y_test==2,y_test==7)\n",
    "\n",
    "x_train = x_train[train_picks]\n",
    "x_test = x_test[test_picks]\n",
    "y_train = np.array(y_train[train_picks]==7,dtype=int)\n",
    "y_test = np.array(y_test[test_picks]==7,dtype=int)\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
